{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.6.tar.gz (84 kB)\n",
      "     ---------------------------------------- 0.0/84.6 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 30.7/84.6 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 30.7/84.6 kB ? eta -:--:--\n",
      "     ------------------------------------ - 81.9/84.6 kB 573.4 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 81.9/84.6 kB 573.4 kB/s eta 0:00:01\n",
      "     -------------------------------------- 84.6/84.6 kB 395.3 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\shivams\\envs\\final\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\shivams\\envs\\final\\lib\\site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\shivams\\envs\\final\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\users\\shivams\\envs\\final\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shivams\\envs\\final\\lib\\site-packages (from kaggle) (4.66.2)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\shivams\\envs\\final\\lib\\site-packages (from kaggle) (1.26.18)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting webencodings (from bleach->kaggle)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shivams\\envs\\final\\lib\\site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shivams\\envs\\final\\lib\\site-packages (from requests->kaggle) (3.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\shivams\\envs\\final\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.8 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 30.7/162.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 122.9/162.8 kB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 153.6/162.8 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 162.8/162.8 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.2 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 30.7/78.2 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 30.7/78.2 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 30.7/78.2 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 30.7/78.2 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 71.7/78.2 kB 302.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.2/78.2 kB 255.3 kB/s eta 0:00:00\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.6-py3-none-any.whl size=111953 sha256=068c501c2f98c11094e1ca49c455ebf1e1903ec416db76eaa2b7d0e29a3b22e0\n",
      "  Stored in directory: c:\\users\\shivams\\appdata\\local\\pip\\cache\\wheels\\46\\aa\\c3\\b3e421522fb5acdd7c366a05c5fc80787615bdeed207e7f79b\n",
      "Successfully built kaggle\n",
      "Installing collected packages: webencodings, text-unidecode, python-slugify, bleach, kaggle\n",
      "Successfully installed bleach-6.1.0 kaggle-1.6.6 python-slugify-8.0.4 text-unidecode-1.3 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuring the path of Kaggle.json file\n",
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json ---- for colab\n",
    "\n",
    "# mkdir -p %HOMEPATH%\\.kaggle\n",
    "# copy /path/to/kaggle.json %HOMEPATH%\\.kaggle\n",
    "# icacls \"%HOMEPATH%\\.kaggle\\kaggle.json\" /grant \"%USERNAME%:(OI)(CI)F\"  ---for windows cmd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Twitter Sentiment Dataset\n",
    "(Using API to fetch the dataset from kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sentiment140.zip to c:\\Users\\shivams\\Desktop\\Sem 4\\Test\\app1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/80.9M [00:00<?, ?B/s]\n",
      "  1%|          | 1.00M/80.9M [00:01<01:51, 748kB/s]\n",
      "  2%|▏         | 2.00M/80.9M [00:01<00:58, 1.41MB/s]\n",
      "  4%|▎         | 3.00M/80.9M [00:03<01:39, 819kB/s] \n",
      "  5%|▍         | 4.00M/80.9M [00:03<01:07, 1.20MB/s]\n",
      "  6%|▌         | 5.00M/80.9M [00:04<00:49, 1.61MB/s]\n",
      "  7%|▋         | 6.00M/80.9M [00:04<00:41, 1.88MB/s]\n",
      "  9%|▊         | 7.00M/80.9M [00:06<01:17, 1.00MB/s]\n",
      " 10%|▉         | 8.00M/80.9M [00:06<00:57, 1.34MB/s]\n",
      " 11%|█         | 9.00M/80.9M [00:07<01:03, 1.19MB/s]\n",
      " 12%|█▏        | 10.0M/80.9M [00:08<00:56, 1.33MB/s]\n",
      " 14%|█▎        | 11.0M/80.9M [00:09<00:58, 1.25MB/s]\n",
      " 15%|█▍        | 12.0M/80.9M [00:10<00:56, 1.27MB/s]\n",
      " 16%|█▌        | 13.0M/80.9M [00:10<00:45, 1.58MB/s]\n",
      " 17%|█▋        | 14.0M/80.9M [00:11<01:01, 1.14MB/s]\n",
      " 19%|█▊        | 15.0M/80.9M [00:12<00:50, 1.36MB/s]\n",
      " 20%|█▉        | 16.0M/80.9M [00:12<00:40, 1.69MB/s]\n",
      " 21%|██        | 17.0M/80.9M [00:13<00:52, 1.28MB/s]\n",
      " 22%|██▏       | 18.0M/80.9M [00:14<00:40, 1.64MB/s]\n",
      " 23%|██▎       | 19.0M/80.9M [00:14<00:35, 1.84MB/s]\n",
      " 25%|██▍       | 20.0M/80.9M [00:14<00:29, 2.17MB/s]\n",
      " 26%|██▌       | 21.0M/80.9M [00:15<00:27, 2.28MB/s]\n",
      " 27%|██▋       | 22.0M/80.9M [00:16<00:46, 1.32MB/s]\n",
      " 28%|██▊       | 23.0M/80.9M [00:17<00:42, 1.43MB/s]\n",
      " 30%|██▉       | 24.0M/80.9M [00:19<00:56, 1.05MB/s]\n",
      " 31%|███       | 25.0M/80.9M [00:19<00:49, 1.18MB/s]\n",
      " 32%|███▏      | 26.0M/80.9M [00:20<00:42, 1.37MB/s]\n",
      " 33%|███▎      | 27.0M/80.9M [00:21<00:42, 1.32MB/s]\n",
      " 35%|███▍      | 28.0M/80.9M [00:21<00:33, 1.68MB/s]\n",
      " 36%|███▌      | 29.0M/80.9M [00:21<00:28, 1.94MB/s]\n",
      " 37%|███▋      | 30.0M/80.9M [00:23<00:50, 1.06MB/s]\n",
      " 38%|███▊      | 31.0M/80.9M [00:24<00:40, 1.30MB/s]\n",
      " 40%|███▉      | 32.0M/80.9M [00:24<00:31, 1.63MB/s]\n",
      " 41%|████      | 33.0M/80.9M [00:24<00:28, 1.75MB/s]\n",
      " 42%|████▏     | 34.0M/80.9M [00:25<00:26, 1.89MB/s]\n",
      " 43%|████▎     | 35.0M/80.9M [00:27<00:44, 1.08MB/s]\n",
      " 44%|████▍     | 36.0M/80.9M [00:28<00:42, 1.12MB/s]\n",
      " 46%|████▌     | 37.0M/80.9M [00:28<00:32, 1.41MB/s]\n",
      " 47%|████▋     | 38.0M/80.9M [00:29<00:38, 1.17MB/s]\n",
      " 48%|████▊     | 39.0M/80.9M [00:29<00:29, 1.50MB/s]\n",
      " 49%|████▉     | 40.0M/80.9M [00:30<00:23, 1.86MB/s]\n",
      " 51%|█████     | 41.0M/80.9M [00:30<00:18, 2.29MB/s]\n",
      " 52%|█████▏    | 42.0M/80.9M [00:32<00:32, 1.25MB/s]\n",
      " 53%|█████▎    | 43.0M/80.9M [00:32<00:31, 1.26MB/s]\n",
      " 54%|█████▍    | 44.0M/80.9M [00:33<00:26, 1.46MB/s]\n",
      " 56%|█████▌    | 45.0M/80.9M [00:33<00:20, 1.82MB/s]\n",
      " 57%|█████▋    | 46.0M/80.9M [00:34<00:19, 1.91MB/s]\n",
      " 58%|█████▊    | 47.0M/80.9M [00:34<00:15, 2.26MB/s]\n",
      " 59%|█████▉    | 48.0M/80.9M [00:34<00:14, 2.38MB/s]\n",
      " 61%|██████    | 49.0M/80.9M [00:34<00:12, 2.77MB/s]\n",
      " 62%|██████▏   | 50.0M/80.9M [00:35<00:10, 3.18MB/s]\n",
      " 63%|██████▎   | 51.0M/80.9M [00:35<00:08, 3.56MB/s]\n",
      " 64%|██████▍   | 52.0M/80.9M [00:35<00:07, 3.92MB/s]\n",
      " 65%|██████▌   | 53.0M/80.9M [00:36<00:09, 3.16MB/s]\n",
      " 67%|██████▋   | 54.0M/80.9M [00:36<00:08, 3.51MB/s]\n",
      " 68%|██████▊   | 55.0M/80.9M [00:38<00:19, 1.42MB/s]\n",
      " 69%|██████▉   | 56.0M/80.9M [00:38<00:15, 1.67MB/s]\n",
      " 70%|███████   | 57.0M/80.9M [00:38<00:12, 2.01MB/s]\n",
      " 72%|███████▏  | 58.0M/80.9M [00:39<00:11, 2.10MB/s]\n",
      " 73%|███████▎  | 59.0M/80.9M [00:39<00:13, 1.69MB/s]\n",
      " 74%|███████▍  | 60.0M/80.9M [00:40<00:11, 1.94MB/s]\n",
      " 75%|███████▌  | 61.0M/80.9M [00:41<00:14, 1.46MB/s]\n",
      " 77%|███████▋  | 62.0M/80.9M [00:41<00:10, 1.84MB/s]\n",
      " 78%|███████▊  | 63.0M/80.9M [00:42<00:09, 2.00MB/s]\n",
      " 79%|███████▉  | 64.0M/80.9M [00:42<00:08, 2.05MB/s]\n",
      " 80%|████████  | 65.0M/80.9M [00:43<00:07, 2.14MB/s]\n",
      " 82%|████████▏ | 66.0M/80.9M [00:43<00:07, 2.22MB/s]\n",
      " 83%|████████▎ | 67.0M/80.9M [00:44<00:07, 2.05MB/s]\n",
      " 84%|████████▍ | 68.0M/80.9M [00:44<00:05, 2.34MB/s]\n",
      " 85%|████████▌ | 69.0M/80.9M [00:44<00:04, 2.51MB/s]\n",
      " 87%|████████▋ | 70.0M/80.9M [00:44<00:04, 2.86MB/s]\n",
      " 88%|████████▊ | 71.0M/80.9M [00:45<00:03, 3.25MB/s]\n",
      " 89%|████████▉ | 72.0M/80.9M [00:45<00:02, 3.50MB/s]\n",
      " 90%|█████████ | 73.0M/80.9M [00:45<00:02, 3.76MB/s]\n",
      " 91%|█████████▏| 74.0M/80.9M [00:45<00:01, 4.39MB/s]\n",
      " 93%|█████████▎| 75.0M/80.9M [00:46<00:01, 3.50MB/s]\n",
      " 94%|█████████▍| 76.0M/80.9M [00:46<00:01, 3.61MB/s]\n",
      " 95%|█████████▌| 77.0M/80.9M [00:46<00:01, 3.10MB/s]\n",
      " 96%|█████████▋| 78.0M/80.9M [00:48<00:01, 1.85MB/s]\n",
      " 98%|█████████▊| 79.0M/80.9M [00:49<00:01, 1.22MB/s]\n",
      " 99%|█████████▉| 80.0M/80.9M [00:50<00:00, 1.31MB/s]\n",
      "100%|██████████| 80.9M/80.9M [00:52<00:00, 809kB/s] \n",
      "100%|██████████| 80.9M/80.9M [00:52<00:00, 1.61MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is extracted successfully...\n"
     ]
    }
   ],
   "source": [
    "#Extracting the compressed dataset\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "dataset = 'Dataset/sentiment140.zip'\n",
    "\n",
    "with ZipFile(dataset, 'r') as zip:\n",
    "    zip.extractall()\n",
    "    print('The data is extracted successfully...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shivams\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#printing the stopwords in English\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data from csv file to pandas dataframe\n",
    "df = pd.read_csv('Dataset/training.1600000.processed.noemoticon.csv', encoding = 'ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the no of rows and columns in the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the 1st five rows in the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the name of the columns and reading the data again\n",
    "\n",
    "column_names = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "df = pd.read_csv('Dataset/training.1600000.processed.noemoticon.csv',names = column_names,encoding = 'ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "id        0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the missing values in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "4    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the Distribution of target column\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the target value from 4(positive) to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'target' : {4 : 1}}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "1    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 --> Negative tweet 1--> Positive tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming (Reducing a word to its root word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "  stemmed_content = re.sub('[^a-zA-Z]', ' ', content)\n",
    "  stemmed_content = stemmed_content.lower()\n",
    "  stemmed_content = stemmed_content.split()\n",
    "  stemmed_content = [stemmer.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "  stemmed_content = ' '.join(stemmed_content)\n",
    "\n",
    "  return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmed_content'] = df['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>switchfoot http twitpic com zl awww bummer sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>kenichan dive mani time ball manag save rest g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>nationwideclass behav mad see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                     stemmed_content  \n",
       "0  switchfoot http twitpic com zl awww bummer sho...  \n",
       "1  upset updat facebook text might cri result sch...  \n",
       "2  kenichan dive mani time ball manag save rest g...  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4                      nationwideclass behav mad see  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('Stemmed_data.csv')\n",
    "# Storing to directly use the data for training purpose from stracth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          switchfoot http twitpic com zl awww bummer sho...\n",
      "1          upset updat facebook text might cri result sch...\n",
      "2          kenichan dive mani time ball manag save rest g...\n",
      "3                            whole bodi feel itchi like fire\n",
      "4                              nationwideclass behav mad see\n",
      "                                 ...                        \n",
      "1599995                           woke school best feel ever\n",
      "1599996    thewdb com cool hear old walt interview http b...\n",
      "1599997                         readi mojo makeov ask detail\n",
      "1599998    happi th birthday boo alll time tupac amaru sh...\n",
      "1599999    happi charitytuesday thenspcc sparkschar speak...\n",
      "Name: stemmed_content, Length: 1600000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['stemmed_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3          0\n",
      "4          0\n",
      "          ..\n",
      "1599995    1\n",
      "1599996    1\n",
      "1599997    1\n",
      "1599998    1\n",
      "1599999    1\n",
      "Name: target, Length: 1600000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the independent and dependent variable for the model\n",
    "X = df['stemmed_content'].values\n",
    "Y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['switchfoot http twitpic com zl awww bummer shoulda got david carr third day'\n",
      " 'upset updat facebook text might cri result school today also blah'\n",
      " 'kenichan dive mani time ball manag save rest go bound' ...\n",
      " 'readi mojo makeov ask detail'\n",
      " 'happi th birthday boo alll time tupac amaru shakur'\n",
      " 'happi charitytuesday thenspcc sparkschar speakinguph h']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.8, stratify = Y, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1600000,)\n",
      "X_Train shape: (320000,)\n",
      "X_test shape: (1280000,)\n",
      "Y shape: (1600000,)\n",
      "Y_train shape: (320000,)\n",
      "Y_test shape: (1280000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"X_Train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Y shape: {Y.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")\n",
    "print(f\"Y_test shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the textual data into numeric data\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "x_train = vectorizer.fit_transform(X_train)\n",
    "x_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 48457)\t0.1783487752665268\n",
      "  (0, 43092)\t0.386842350151501\n",
      "  (0, 167850)\t0.240111467402399\n",
      "  (0, 14346)\t0.39931315003032014\n",
      "  (0, 91021)\t0.12279231293768048\n",
      "  (0, 64953)\t0.2818926236771396\n",
      "  (0, 3258)\t0.268863609257796\n",
      "  (0, 169337)\t0.19699933564194627\n",
      "  (0, 2267)\t0.386842350151501\n",
      "  (0, 102778)\t0.29737947041409823\n",
      "  (0, 97427)\t0.34420440374144945\n",
      "  (0, 149213)\t0.14186208446047013\n",
      "  (0, 69568)\t0.13827271618536066\n",
      "  (1, 139545)\t0.29888555194176414\n",
      "  (1, 171582)\t0.2484903566305166\n",
      "  (1, 58742)\t0.23532123603321103\n",
      "  (1, 22248)\t0.4730975135632803\n",
      "  (1, 111490)\t0.35682891305058717\n",
      "  (1, 111560)\t0.368031863026555\n",
      "  (1, 138990)\t0.24788749337516608\n",
      "  (1, 176380)\t0.1987217801344402\n",
      "  (1, 24464)\t0.4538829666013753\n",
      "  (2, 103158)\t0.25289862472456276\n",
      "  (2, 56932)\t0.1349989426882956\n",
      "  (2, 173386)\t0.14393122231218733\n",
      "  :\t:\n",
      "  (319997, 129705)\t0.5577275171539521\n",
      "  (319997, 18924)\t0.5338276940914474\n",
      "  (319997, 87368)\t0.34981217879815113\n",
      "  (319997, 34978)\t0.30029306772079845\n",
      "  (319997, 154802)\t0.2988546107238569\n",
      "  (319997, 11330)\t0.31954568424985874\n",
      "  (319998, 94980)\t0.49753220129691644\n",
      "  (319998, 21372)\t0.4511454881046659\n",
      "  (319998, 13180)\t0.41294531532644624\n",
      "  (319998, 67037)\t0.3837307012513296\n",
      "  (319998, 172602)\t0.32819047139879703\n",
      "  (319998, 152967)\t0.26675832885104533\n",
      "  (319998, 157808)\t0.22866434171987776\n",
      "  (319999, 165448)\t0.46641176127139244\n",
      "  (319999, 49776)\t0.4166091447520082\n",
      "  (319999, 67269)\t0.36462858906138074\n",
      "  (319999, 47956)\t0.3691250742132525\n",
      "  (319999, 53003)\t0.3002596409911786\n",
      "  (319999, 125627)\t0.23336910282302076\n",
      "  (319999, 169777)\t0.16678092956801344\n",
      "  (319999, 135551)\t0.17930778087496033\n",
      "  (319999, 85661)\t0.15871651658543676\n",
      "  (319999, 50676)\t0.16025962006723515\n",
      "  (319999, 137693)\t0.257862322704346\n",
      "  (319999, 56932)\t0.1331854205266064\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 176345)\t0.31673609293759325\n",
      "  (0, 129575)\t0.33441300429694437\n",
      "  (0, 102503)\t0.48768515882289265\n",
      "  (0, 33928)\t0.5144388444034379\n",
      "  (0, 4929)\t0.34898850449664237\n",
      "  (0, 2487)\t0.4044367378832719\n",
      "  (1, 165253)\t0.3124214918581995\n",
      "  (1, 129575)\t0.20657819537232627\n",
      "  (1, 125210)\t0.20948004318610883\n",
      "  (1, 108557)\t0.3825896035187392\n",
      "  (1, 102600)\t0.2904331109518877\n",
      "  (1, 92010)\t0.1974158149336613\n",
      "  (1, 65439)\t0.2571496816551475\n",
      "  (1, 65263)\t0.2351833778956644\n",
      "  (1, 63539)\t0.3016449922375899\n",
      "  (1, 62435)\t0.21841244452534805\n",
      "  (1, 61988)\t0.24569058915749686\n",
      "  (1, 55709)\t0.438138420687336\n",
      "  (1, 52767)\t0.18351335897572552\n",
      "  (2, 160188)\t0.21656745725725254\n",
      "  (2, 159248)\t0.24782890623285825\n",
      "  (2, 157808)\t0.1995440258352993\n",
      "  (2, 147581)\t0.5134867769008576\n",
      "  (2, 145914)\t0.30058676471077816\n",
      "  (2, 144083)\t0.22167376527081448\n",
      "  :\t:\n",
      "  (1279995, 101280)\t0.39536998652619587\n",
      "  (1279995, 99397)\t0.220300222649306\n",
      "  (1279995, 87421)\t0.3662534378184293\n",
      "  (1279995, 25090)\t0.2829472557167034\n",
      "  (1279996, 66289)\t0.37368960982460536\n",
      "  (1279996, 60736)\t0.48315507853231443\n",
      "  (1279996, 51519)\t0.5574202616364607\n",
      "  (1279996, 50676)\t0.36360818025442326\n",
      "  (1279996, 15452)\t0.4289393765636046\n",
      "  (1279997, 167096)\t0.5520686299876812\n",
      "  (1279997, 142998)\t0.33993528414685625\n",
      "  (1279997, 82612)\t0.7194443490840025\n",
      "  (1279997, 69568)\t0.2491265922109008\n",
      "  (1279998, 157776)\t0.44709285824187917\n",
      "  (1279998, 150769)\t0.5141406147442388\n",
      "  (1279998, 123151)\t0.5489009550075902\n",
      "  (1279998, 48537)\t0.48422633754400296\n",
      "  (1279999, 142008)\t0.27631633355806984\n",
      "  (1279999, 137946)\t0.27505377719697216\n",
      "  (1279999, 121127)\t0.39676459561338967\n",
      "  (1279999, 116206)\t0.5382466395806922\n",
      "  (1279999, 88472)\t0.24697349894904325\n",
      "  (1279999, 64829)\t0.3612937747923099\n",
      "  (1279999, 51464)\t0.27938913813287874\n",
      "  (1279999, 30918)\t0.3623199176323287\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation\n",
    "\n",
    "Checking the Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy score on the training data\n",
    "X_train_prediction = model.predict(x_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Training Data: 0.8142\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score of Training Data: {training_data_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prediction = model.predict(x_test)\n",
    "\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Testing Data: 0.77080078125\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy Score of Testing Data: {testing_data_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means our model is not overfitted neither underfitted\n",
    "\n",
    "Model Accuracy = 77%\n",
    "\n",
    "Saving the trained Model in a pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer and Logistic Regression model saved successfully...\n"
     ]
    }
   ],
   "source": [
    "#Create a dictionary\n",
    "data = {'vectorizer': vectorizer, 'model' : model}\n",
    "\n",
    "#Save the dictionary to a pickle file\n",
    "filename = 'model_and_vectorizer.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "print(\"TF-IDF Vectorizer and Logistic Regression model saved successfully...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer and Logistic Regression model saved successfully as sav...\n"
     ]
    }
   ],
   "source": [
    "# Save the dictionary to a pickle file\n",
    "filename = 'model_and_vectorizer.sav'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "print(\"TF-IDF Vectorizer and Logistic Regression model saved successfully as sav...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the created model for future prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new = \"Elena is getting late every day, I think we should ban her\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_and_vectorizer.pkl'  # Or 'text_classifier.pkl' depending on the method\n",
    "\n",
    "# Load the data\n",
    "with open(filename, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vectorizer = data['vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = data['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elena get late everi day think ban\n"
     ]
    }
   ],
   "source": [
    "processed_input = stemming(test_new)\n",
    "print(processed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['elena get late everi day think ban']], dtype='<U34')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([processed_input]).reshape(1, -1)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = ' '.join(X_new[0])  # Assuming X_new is a single-row array\n",
    "X_new_transformed = loaded_vectorizer.transform([processed_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 157808)\t0.2443162995996281\n",
      "  (0, 88518)\t0.32759330113989865\n",
      "  (0, 56932)\t0.20305065552322768\n",
      "  (0, 48477)\t0.3527453665516711\n",
      "  (0, 45437)\t0.6129428915426676\n",
      "  (0, 36622)\t0.2049615291376428\n",
      "  (0, 12569)\t0.4996249550883103\n"
     ]
    }
   ],
   "source": [
    "print(X_new_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = loaded_model.predict(X_new_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "if prediction[0] == 0:\n",
    "    print(\"Sentiment: Negative\")\n",
    "else:\n",
    "    print(\"Sentiment: Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
